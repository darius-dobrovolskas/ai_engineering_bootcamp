{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4098e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Prefetch, Filter, FieldCondition, MatchText, FusionQuery\n",
    "\n",
    "from langsmith import traceable, get_current_run_tree\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "from jinja2 import Template\n",
    "from typing import Literal, Dict, Any, Annotated, List, Optional\n",
    "from IPython.display import Image, display\n",
    "from operator import add\n",
    "from openai import OpenAI\n",
    "\n",
    "import openai\n",
    "\n",
    "import random\n",
    "import ast\n",
    "import inspect\n",
    "import instructor\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a45955",
   "metadata": {},
   "source": [
    "* Code has persistent state storage (memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae92372",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7917c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function_definition(function_def: str) -> Dict[str, Any]:\n",
    "    \"\"\"Parse a function definition string to extract metadata including type hints.\"\"\"\n",
    "    result = {\n",
    "        \"name\": \"\",\n",
    "        \"description\": \"\",\n",
    "        \"parameters\": {\"type\": \"object\", \"properties\": {}},\n",
    "        \"required\": [],\n",
    "        \"returns\": {\"type\": \"string\", \"description\": \"\"}\n",
    "    }\n",
    "    \n",
    "    # Parse the function using AST\n",
    "    tree = ast.parse(function_def.strip())\n",
    "    if not tree.body or not isinstance(tree.body[0], ast.FunctionDef):\n",
    "        return result\n",
    "        \n",
    "    func = tree.body[0]\n",
    "    result[\"name\"] = func.name\n",
    "    \n",
    "    # Extract docstring\n",
    "    docstring = ast.get_docstring(func) or \"\"\n",
    "    if docstring:\n",
    "        # Extract description (first line/paragraph)\n",
    "        desc_end = docstring.find('\\n\\n') if '\\n\\n' in docstring else docstring.find('\\nArgs:')\n",
    "        desc_end = desc_end if desc_end > 0 else docstring.find('\\nParameters:')\n",
    "        result[\"description\"] = docstring[:desc_end].strip() if desc_end > 0 else docstring.strip()\n",
    "        \n",
    "        # Parse parameter descriptions\n",
    "        param_descs = parse_docstring_params(docstring)\n",
    "        \n",
    "        # Extract return description\n",
    "        if \"Returns:\" in docstring:\n",
    "            result[\"returns\"][\"description\"] = docstring.split(\"Returns:\")[1].strip().split('\\n')[0]\n",
    "    \n",
    "    # Extract parameters with type hints\n",
    "    args = func.args\n",
    "    defaults = args.defaults\n",
    "    num_args = len(args.args)\n",
    "    num_defaults = len(defaults)\n",
    "    \n",
    "    for i, arg in enumerate(args.args):\n",
    "        if arg.arg == 'self':\n",
    "            continue\n",
    "            \n",
    "        param_info = {\n",
    "            \"type\": get_type_from_annotation(arg.annotation) if arg.annotation else \"string\",\n",
    "            \"description\": param_descs.get(arg.arg, \"\")\n",
    "        }\n",
    "        \n",
    "        # Check for default value\n",
    "        default_idx = i - (num_args - num_defaults)\n",
    "        if default_idx >= 0:\n",
    "            param_info[\"default\"] = ast.literal_eval(ast.unparse(defaults[default_idx]))\n",
    "        else:\n",
    "            result[\"required\"].append(arg.arg)\n",
    "        \n",
    "        result[\"parameters\"][\"properties\"][arg.arg] = param_info\n",
    "    \n",
    "    # Extract return type\n",
    "    if func.returns:\n",
    "        result[\"returns\"][\"type\"] = get_type_from_annotation(func.returns)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def get_type_from_annotation(annotation) -> str:\n",
    "    \"\"\"Convert AST annotation to type string.\"\"\"\n",
    "    if not annotation:\n",
    "        return \"string\"\n",
    "    \n",
    "    type_map = {\n",
    "        'str': 'string',\n",
    "        'int': 'integer', \n",
    "        'float': 'number',\n",
    "        'bool': 'boolean',\n",
    "        'list': 'array',\n",
    "        'dict': 'object',\n",
    "        'List': 'array',\n",
    "        'Dict': 'object'\n",
    "    }\n",
    "    \n",
    "    if isinstance(annotation, ast.Name):\n",
    "        return type_map.get(annotation.id, annotation.id)\n",
    "    elif isinstance(annotation, ast.Subscript) and isinstance(annotation.value, ast.Name):\n",
    "        base_type = annotation.value.id\n",
    "        return type_map.get(base_type, base_type.lower())\n",
    "    \n",
    "    return \"string\"\n",
    "\n",
    "\n",
    "def parse_docstring_params(docstring: str) -> Dict[str, str]:\n",
    "    \"\"\"Extract parameter descriptions from docstring (handles both Args: and Parameters: formats).\"\"\"\n",
    "    params = {}\n",
    "    lines = docstring.split('\\n')\n",
    "    in_params = False\n",
    "    current_param = None\n",
    "    \n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        \n",
    "        # Check for parameter section start\n",
    "        if stripped in ['Args:', 'Arguments:', 'Parameters:', 'Params:']:\n",
    "            in_params = True\n",
    "            current_param = None\n",
    "        elif stripped.startswith('Returns:') or stripped.startswith('Raises:'):\n",
    "            in_params = False\n",
    "        elif in_params:\n",
    "            # Parse parameter line (handles \"param: desc\" and \"- param: desc\" formats)\n",
    "            if ':' in stripped and (stripped[0].isalpha() or stripped.startswith(('-', '*'))):\n",
    "                param_name = stripped.lstrip('- *').split(':')[0].strip()\n",
    "                param_desc = ':'.join(stripped.lstrip('- *').split(':')[1:]).strip()\n",
    "                params[param_name] = param_desc\n",
    "                current_param = param_name\n",
    "            elif current_param and stripped:\n",
    "                # Continuation of previous parameter description\n",
    "                params[current_param] += ' ' + stripped\n",
    "    \n",
    "    return params\n",
    "\n",
    "\n",
    "def get_tool_descriptions_from_node(tool_node):\n",
    "    \"\"\"Extract tool descriptions from the ToolNode object.\"\"\"\n",
    "    descriptions = []\n",
    "    \n",
    "    if hasattr(tool_node, 'tools_by_name'):\n",
    "        tools_by_name = tool_node.tools_by_name\n",
    "        \n",
    "        for tool_name, tool in tools_by_name.items():\n",
    "            function_string = inspect.getsource(globals()[tool_name])\n",
    "            # function_string = inspect.getsource(getattr(tool_name))\n",
    "            result = parse_function_definition(function_string)\n",
    "\n",
    "            if result:\n",
    "                descriptions.append(result)\n",
    "    \n",
    "    return descriptions if descriptions else \"Could not extract tool descriptions\"\n",
    "\n",
    "\n",
    "def lc_messages_to_regular_messages(msg):\n",
    "    \"\"\"Transforms LangChain messages to OpenAi compatible message format.\"\"\"\n",
    "\n",
    "    if isinstance(msg, dict):\n",
    "        \n",
    "        if msg.get(\"role\") == \"user\":\n",
    "            return {\"role\": \"user\", \"content\": msg[\"content\"]}\n",
    "        elif msg.get(\"role\") == \"assistant\":\n",
    "            return {\"role\": \"assistant\", \"content\": msg[\"content\"]}\n",
    "        elif msg.get(\"role\") == \"tool\":\n",
    "            return {\n",
    "                \"role\": \"tool\", \n",
    "                \"content\": msg[\"content\"], \n",
    "                \"tool_call_id\": msg.get(\"tool_call_id\")\n",
    "            }\n",
    "        \n",
    "    elif isinstance(msg, AIMessage):\n",
    "\n",
    "        result = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": msg.content\n",
    "        }\n",
    "        \n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls and len(msg.tool_calls) > 0 and not msg.tool_calls[0].get(\"name\").startswith(\"functions.\"):\n",
    "            result[\"tool_calls\"] = [\n",
    "                {\n",
    "                    \"id\": tc[\"id\"],\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tc[\"name\"].replace(\"functions.\", \"\"),\n",
    "                        \"arguments\": json.dumps(tc[\"args\"])\n",
    "                    }\n",
    "                }\n",
    "                for tc in msg.tool_calls\n",
    "            ]\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    elif isinstance(msg, ToolMessage):\n",
    "\n",
    "        return {\"role\": \"tool\", \"content\": msg.content, \"tool_call_id\": msg.tool_call_id}\n",
    "    \n",
    "    else:\n",
    "\n",
    "        return {\"role\": \"user\", \"content\": str(msg)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebabd23",
   "metadata": {},
   "source": [
    "### Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f504bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "        name=\"embed_query\",\n",
    "        run_type=\"embedding\",\n",
    "        metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"text-embedding-3-small\"}\n",
    ")\n",
    "def get_embedding(text, \n",
    "                  model=\"text-embedding-3-small\"):\n",
    "    response = openai.embeddings.create(\n",
    "        input=[text],\n",
    "        model=model\n",
    "    )\n",
    "\n",
    "    current_run = get_current_run_tree()\n",
    "    if current_run:\n",
    "        current_run.metadata[\"usage_metadata\"] = {\n",
    "            \"input_tokens\": response.usage.prompt_tokens,\n",
    "            \"total_tokens\": response.usage.total_tokens\n",
    "        }\n",
    "\n",
    "    return response.data[0].embedding\n",
    "\n",
    "@traceable(\n",
    "        name=\"retrieve_top_n\",\n",
    "        run_type=\"retriever\"\n",
    ")\n",
    "def retrieve_context(query, top_k):\n",
    "\n",
    "    query_embedding = get_embedding(query)\n",
    "\n",
    "    qdrant_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "    results = qdrant_client.query_points(\n",
    "        collection_name=\"Amazon-items-collection-01-hybrid\", # config.QDRANT_COLLECTION_NAME   \n",
    "        prefetch=[\n",
    "            Prefetch(\n",
    "                query=query_embedding,\n",
    "                limit=20\n",
    "            ),\n",
    "            Prefetch(\n",
    "                filter=Filter(\n",
    "                    must=[\n",
    "                        FieldCondition(\n",
    "                            key=\"text\",\n",
    "                            match=MatchText(text=query)\n",
    "                        )\n",
    "                    ]\n",
    "                ),\n",
    "                limit=20\n",
    "            )\n",
    "        ],\n",
    "        query=FusionQuery(fusion=\"rrf\"),\n",
    "        limit=top_k\n",
    "    )\n",
    "\n",
    "    retrieved_context_ids = []\n",
    "    retrieved_context = []\n",
    "    similarity_scores = []\n",
    "\n",
    "    for result in results.points:\n",
    "        retrieved_context_ids.append(result.id)\n",
    "        retrieved_context.append(result.payload[\"text\"])\n",
    "        similarity_scores.append(result.score)\n",
    "\n",
    "    return {\n",
    "        \"retrieved_context_ids\": retrieved_context_ids,\n",
    "        \"retrieved_context\": retrieved_context,\n",
    "        \"similarity_scores\": similarity_scores\n",
    "    }\n",
    "\n",
    "@traceable(\n",
    "        name=\"format_retrieved_context\",\n",
    "        run_type=\"prompt\"\n",
    ")\n",
    "def process_context(context):\n",
    "    formatted_context = \"\"\n",
    "\n",
    "    for id, chunk in zip(context[\"retrieved_context_ids\"], context[\"retrieved_context\"]):\n",
    "        formatted_context += f\"- {id}: {chunk}\\n\" \n",
    "\n",
    "    return formatted_context\n",
    "\n",
    "def get_formatted_context(query: str, top_k: int = 5) -> str:\n",
    "    \"\"\"Get the top k context, each representing an inventory item for a given query.\n",
    "    \n",
    "    Args:\n",
    "        query: The query to get the top k context for\n",
    "        top_k: The number of context chunks to retrieve, works best with 5 or more\n",
    "     \n",
    "    Returns:\n",
    "        A string of the top k context chunks with IDs prepending each chunk, each representing an inventory item for a given query.\n",
    "    \"\"\"\n",
    "    # copy/paste from rag_pipeline() in retrieval.py\n",
    "    context = retrieve_context(query, top_k)\n",
    "    formatted_context = process_context(context)\n",
    "\n",
    "    return formatted_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e61f6",
   "metadata": {},
   "source": [
    "### State and Pydantic Models for structured outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55fd43d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "\n",
    "class RAGUsedContext(BaseModel):\n",
    "    id: int\n",
    "    description: str\n",
    "\n",
    "class AgentResponse(BaseModel):\n",
    "    answer: str\n",
    "    tool_calls: List[ToolCall] = Field(default_factory=list)\n",
    "    final_answer: bool = Field(default=False)\n",
    "    retrieved_context_ids: List[RAGUsedContext]\n",
    "\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[List[Any], add] = []\n",
    "    answer: str = \"\"\n",
    "    iteration: int = Field(default=0)\n",
    "    final_answer: bool = Field(default=False)\n",
    "    available_tools: List[Dict[str, Any]] = []\n",
    "    tool_calls: Optional[List[ToolCall]] = Field(default_factory=list)\n",
    "    retrieved_context_ids: Annotated[List[RAGUsedContext], add] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a39e2e5",
   "metadata": {},
   "source": [
    "### Agent node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15dc9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"agent_node\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1-mini\"}\n",
    ")\n",
    "def agent_node(state: State) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are a shopping assistant that can answer questions about the products in stock.\n",
    "\n",
    "You will be given a question and a list of tools you can use to answer that question.\n",
    "\n",
    "<Available tools>\n",
    "{{ available_tools | tojson }}\n",
    "</Available tools>\n",
    "\n",
    "After the tools are used you will get the outputs from the tools.\n",
    "\n",
    "When you need to use a tool, format your response as:\n",
    "\n",
    "<tool_call>\n",
    "{\"name\": \"tool_name\", \"arguments\": {...}}\n",
    "</tool_call>\n",
    "\n",
    "Use names specificly provided in the available tools. Don't add any additional text to the names.\n",
    "\n",
    "You should tend to use tools when additional information is needed to answer the question.\n",
    "\n",
    "If you set final_answer to True, you should not use any tools.\n",
    "\n",
    "Instructions:\n",
    "- You need to answer the question based on the retrieved context using the available tools only.\n",
    "- Never use word context and refer to it as the available products.\n",
    "- You should only answer questions about the products in stock. If the question is not about the products in stock, you should ask for clarification.\n",
    "- As a final output you need to provide:\n",
    "\n",
    "* The answer to the question based on the retrieved context.\n",
    "* The list of the indexes from the chunks returned from all tool calls that were used to answer the question. If more than one chunk was used to compile the answer from a single tool call, be sure to return all of them.\n",
    "* Short description of the item based on the retrieved context.\n",
    "\n",
    "- The answer to the question should contain detailed information about the product and returned with detailed specification in bullet points.\n",
    "- The short description should have the name of the item.\n",
    "- If the user's request requires using a tool, set tool_calls with the appropriate function name and arguments.\n",
    "- If you have all the information needed to provide a complete answer, set final_answer to True.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      available_tools=state.available_tools\n",
    "   )\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for msg in messages:\n",
    "      conversation.append(lc_messages_to_regular_messages(msg))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        response_model=AgentResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0.5,\n",
    "   )\n",
    "\n",
    "   if response.tool_calls:\n",
    "      tool_calls = []\n",
    "      for i, tc in enumerate(response.tool_calls):\n",
    "         tool_calls.append({\n",
    "               \"id\": f\"call_{i}\",\n",
    "               \"name\": tc.name,\n",
    "               \"args\": tc.arguments\n",
    "         })\n",
    "\n",
    "      ai_message = AIMessage(\n",
    "         content=response.answer,\n",
    "         tool_calls=tool_calls\n",
    "         )\n",
    "   else:\n",
    "      ai_message = AIMessage(\n",
    "         content=response.answer,\n",
    "      )\n",
    "\n",
    "   return {\n",
    "      \"messages\": [ai_message],\n",
    "      \"tool_calls\": response.tool_calls,\n",
    "      \"iteration\": state.iteration + 1,\n",
    "      \"answer\": response.answer,\n",
    "      \"final_answer\": response.final_answer,\n",
    "      \"retrieve_context_ids\": response.retrieved_context_ids\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc36a8ca",
   "metadata": {},
   "source": [
    "### Router node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37180bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_router(state: State) -> str:\n",
    "    \"\"\"Decide whether to continue or end\"\"\"\n",
    "    if state.final_answer:\n",
    "        return \"end\"\n",
    "    elif state.iteration > 2:\n",
    "        return \"end\"\n",
    "    elif len(state.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0bbe90",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d30006d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "tools = [get_formatted_context]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "tool_descriptions = get_tool_descriptions_from_node(tool_node)\n",
    "\n",
    "workflow.add_node(\"agent node\", agent_node)\n",
    "workflow.add_node(\"tool_node\", tool_node)   \n",
    "\n",
    "workflow.add_edge(START, \"agent node\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent node\", \n",
    "    tool_router,\n",
    "    {\n",
    "        \"tools\": \"tool_node\", \n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tool_node\", \"agent node\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d38180f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ecb243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_state = {\n",
    "#     \"messages\": [{\"role\": \"user\", \"content\": \"Can I get earphones for myself, a laptop bag for my wife and something cool for my kids?\"}],\n",
    "#     \"available_tools\": tool_descriptions\n",
    "# }\n",
    "# result = graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1757c1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79be9194",
   "metadata": {},
   "source": [
    "### Persistent state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276bcd59",
   "metadata": {},
   "source": [
    "* PostgresSaver is a context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e03c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.postgres import PostgresSaver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c147ceef",
   "metadata": {},
   "source": [
    "* IMPORTANT: Run this ONCE to setup postgresDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f6d9b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mPostgresSaver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_conn_string\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpostgresql://langgraph_user:langgraph_password@localhost:5433/langgraph_db\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dariu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai-engineering-bootcamp-sL1ZxK4x-py3.12\\Lib\\site-packages\\langgraph\\checkpoint\\postgres\\__init__.py:68\u001b[39m, in \u001b[36mPostgresSaver.from_conn_string\u001b[39m\u001b[34m(cls, conn_string, pipeline)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_conn_string\u001b[39m(\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mcls\u001b[39m, conn_string: \u001b[38;5;28mstr\u001b[39m, *, pipeline: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     58\u001b[39m ) -> Iterator[PostgresSaver]:\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a new PostgresSaver instance from a connection string.\u001b[39;00m\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m \u001b[33;03m        PostgresSaver: A new PostgresSaver instance.\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mConnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconn_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepare_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdict_row\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m     71\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m pipeline:\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m conn.pipeline() \u001b[38;5;28;01mas\u001b[39;00m pipe:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dariu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai-engineering-bootcamp-sL1ZxK4x-py3.12\\Lib\\site-packages\\psycopg\\connection.py:110\u001b[39m, in \u001b[36mConnection.connect\u001b[39m\u001b[34m(cls, conninfo, autocommit, prepare_threshold, context, row_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    108\u001b[39m     conn_errors.append((ex, descr))\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m e._NO_TRACEBACK \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ex.with_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    112\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33mconnection succeeded: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, descr)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "with PostgresSaver.from_conn_string(\"postgresql://langgraph_user:langgraph_password@localhost:5433/langgraph_db\") as checkpointer:\n",
    "\n",
    "    checkpointer.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb96add1",
   "metadata": {},
   "source": [
    "* State will persist in postgresDB. When we invoke the same graph with the same thread_id (test000) the second time it will pull previous state. See LangSmith for tracing outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52673c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = \"test007\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e4462d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Can I get earphones for myself, a laptop bag for my wife and something cool for my kids?\"}],\n",
    "    \"available_tools\": tool_descriptions\n",
    "}\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "with PostgresSaver.from_conn_string(\"postgresql://langgraph_user:langgraph_password@localhost:5433/langgraph_db\") as checkpointer:\n",
    "\n",
    "    graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "    graph.invoke(state, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90ce1559",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"And what of these are waterproof and outdoors friendly?\"}],\n",
    "    \"iteration\": 0,\n",
    "    \"available_tools\": tool_descriptions\n",
    "}\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "with PostgresSaver.from_conn_string(\"postgresql://langgraph_user:langgraph_password@localhost:5433/langgraph_db\") as checkpointer:\n",
    "\n",
    "    graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "    graph.invoke(state, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "686c101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Can you get me a speaker, I would like to get at least six suggestions?\"}],\n",
    "    \"iteration\": 0,\n",
    "    \"available_tools\": tool_descriptions\n",
    "}\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "with PostgresSaver.from_conn_string(\"postgresql://langgraph_user:langgraph_password@localhost:5433/langgraph_db\") as checkpointer:\n",
    "\n",
    "    graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "    graph.invoke(state, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b7045d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e0584a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-engineering-bootcamp-sL1ZxK4x-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
